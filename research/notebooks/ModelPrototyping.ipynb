{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import zipfile\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"../../data/raw/\"\n",
    "PROCESSED_DATA_PATH = \"../../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(value, filename):\n",
    "    if value is not None and filename is not None:\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Please provide a valid path\".capitalize())\n",
    "    \n",
    "def load(filename):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename=filename)\n",
    "    else: \n",
    "        raise Exception(\"Please provide a valid path\".capitalize())\n",
    "    \n",
    "def clean():\n",
    "    if os.path.exists(RAW_DATA_PATH):\n",
    "        directory = os.listdir(RAW_DATA_PATH)\n",
    "\n",
    "        if os.path.isdir(RAW_DATA_PATH):\n",
    "            os.system(\"rm -rf {}\".format(os.path.join(RAW_DATA_PATH, directory[0])))\n",
    "            print(\"done\")\n",
    "        \n",
    "        else:\n",
    "            raise Exception(\"Please provide a valid path\".capitalize())\n",
    "    else:\n",
    "        raise Exception(\"Please provide a valid path\".capitalize())\n",
    "    \n",
    "    if os.path.exists(PROCESSED_DATA_PATH):\n",
    "        \n",
    "        for file in os.listdir(PROCESSED_DATA_PATH):\n",
    "            os.remove(os.path.join(PROCESSED_DATA_PATH, file))\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Please provide a valid path\".capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(DataLoader):\n",
    "    def __init__(self, image_path = None, batch_size = 16, image_size = 64, split_ratio = 0.25):\n",
    "        self.image_path = image_path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.split_ratio = split_ratio\n",
    "\n",
    "        self.clean_images = list()\n",
    "        self.noise_images = list()\n",
    "\n",
    "    def unzip_folder(self):\n",
    "\n",
    "        try:\n",
    "            clean()\n",
    "        except Exception as e:\n",
    "            print(\"The exception is: {}\".format(e))\n",
    "            \n",
    "        if os.path.exists(RAW_DATA_PATH):\n",
    "            with zipfile.ZipFile(self.image_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(os.path.join(RAW_DATA_PATH,))\n",
    "        else:\n",
    "            raise Exception(\"Please provide a valid path\".capitalize())\n",
    "\n",
    "    def image_transforms(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def image_split(self, **kwargs):\n",
    "        return train_test_split(\n",
    "            kwargs[\"noise_images\"], kwargs[\"clean_images\"], test_size=self.split_ratio, random_state=42,\n",
    "        )\n",
    "\n",
    "    def create_dataloader(self):\n",
    "\n",
    "        if os.path.exists(RAW_DATA_PATH):\n",
    "            dataset = os.listdir(RAW_DATA_PATH)[0]\n",
    "\n",
    "            clean_images = os.path.join(RAW_DATA_PATH, dataset, \"clean_images\")\n",
    "            noise_images = os.path.join(RAW_DATA_PATH, dataset, \"noisy_images\")\n",
    "\n",
    "            for image in os.listdir(clean_images):\n",
    "                clean_image_path = os.path.join(clean_images, image)\n",
    "\n",
    "                if image in os.listdir(noise_images):\n",
    "                    noise_image_path = os.path.join(noise_images, image)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                self.clean_images.append(\n",
    "                    self.image_transforms()(\n",
    "                        Image.fromarray(cv2.imread(clean_image_path))))\n",
    "\n",
    "                self.noise_images.append(\n",
    "                    self.image_transforms()(\n",
    "                        Image.fromarray(cv2.imread(noise_image_path))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            try:\n",
    "                image_split = self.image_split(\n",
    "                    clean_images = self.clean_images, noise_images = self.noise_images\n",
    "                    )\n",
    "\n",
    "                dataloader = DataLoader(\n",
    "                    dataset=list(zip(self.noise_images, self.clean_images)), batch_size=self.batch_size*6, shuffle=True\n",
    "                    )\n",
    "\n",
    "                train_dataloader = DataLoader(\n",
    "                    dataset=list(zip(image_split[0], image_split[2])), batch_size=self.batch_size, shuffle=True\n",
    "                    )\n",
    "\n",
    "                test_dataloader = DataLoader(\n",
    "                    dataset=list(zip(image_split[1], image_split[3])), batch_size=self.batch_size, shuffle=True\n",
    "                    )\n",
    "\n",
    "                if os.path.exists(PROCESSED_DATA_PATH):\n",
    "\n",
    "                    dump(value=dataloader, filename=os.path.join(PROCESSED_DATA_PATH, \"dataloader.pkl\"))\n",
    "\n",
    "                    dump(value=train_dataloader, filename=os.path.join(PROCESSED_DATA_PATH, \"train_dataloader.pkl\"))\n",
    "\n",
    "                    dump(value=test_dataloader, filename=os.path.join(PROCESSED_DATA_PATH, \"test_dataloader.pkl\"))\n",
    "                else:\n",
    "                    raise Exception(\"Please provide a valid path\".capitalize())\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"The exception is: {}\".format(e))\n",
    "                \n",
    "            \n",
    "            return dataloader\n",
    "\n",
    "    @staticmethod\n",
    "    def dataset_details():\n",
    "        if os.path.exists(PROCESSED_DATA_PATH):\n",
    "            dataloader = load(filename=os.path.join(PROCESSED_DATA_PATH, \"dataloader.pkl\"))\n",
    "\n",
    "            clean, noise = next(iter(dataloader))\n",
    "\n",
    "            total_data = sum(clean.size(0) for clean, _ in dataloader)\n",
    "\n",
    "            print(\"Total number of images: {}\".format(total_data))\n",
    "            print(\"Clean images shape : {}\".format(clean.size()))\n",
    "            print(\"Noisy images shape : {}\".format(noise.size()))\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Please provide a valid path\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def show_images():\n",
    "        if os.path.exists(PROCESSED_DATA_PATH):\n",
    "            dataloader = load(filename=os.path.join(PROCESSED_DATA_PATH, \"dataloader.pkl\"))\n",
    "        else:\n",
    "            raise Exception(\"Please provide a valid path\".capitalize())\n",
    "\n",
    "        plt.figure(figsize=(40, 15))\n",
    "\n",
    "        noise, clean = next(iter(dataloader))\n",
    "\n",
    "        for index, image in enumerate(noise):\n",
    "            noise_image = image.permute(1, 2, 0)\n",
    "            noise_image = (noise_image - noise_image.min()) / (\n",
    "                noise_image.max() - noise_image.min()\n",
    "            )\n",
    "\n",
    "            clean_image = clean[index].permute(1, 2, 0)\n",
    "            clean_image = (clean_image - clean_image.min()) / (\n",
    "                clean_image.max() - clean_image.min())\n",
    "\n",
    "            plt.subplot(2 * 4, 2 * 6, 2 * index + 1)\n",
    "            plt.imshow(noise_image)\n",
    "            plt.title(\"Noisy\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(2 * 4, 2 * 6, 2 * index + 2)\n",
    "            plt.imshow(clean_image)\n",
    "            plt.title(\"Clean\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(image_path=\"/Users/shahmuhammadraditrahman/Desktop/images.zip\",\n",
    "                    batch_size=4,\n",
    "                    image_size=64,\n",
    "                    split_ratio=0.25)\n",
    "\n",
    "    loader.unzip_folder()\n",
    "    dataloader = loader.create_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(Loader.dataset_details(),\"\\n\\n\")\n",
    "\n",
    "    Loader.show_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
